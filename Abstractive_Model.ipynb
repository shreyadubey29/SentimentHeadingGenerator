{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Created By : Shreya Dubey\n",
    "## Abstractive headline predictor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CmgSwHByjyQL",
    "outputId": "2f5c8a6a-69ae-4ff9-e4e8-e09614c4977e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/44/47f0722aea081697143fbcf5d2aa60d1aee4aaacb5869aee2b568974777b/tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (380.8MB)\n",
      "\u001b[K     |████████████████████████████████| 380.8MB 39kB/s \n",
      "\u001b[?25hCollecting tensorflow-estimator<2.1.0,>=2.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 52.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
      "Collecting tensorboard<2.1.0,>=2.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/9e/a48cd34dd7b672ffc227b566f7d16d63c62c58b542d54efa45848c395dd4/tensorboard-2.0.1-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 50.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.17.4)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.1.8)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.8.0)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/cb/786dc53d93494784935a62947643b48250b84a882474e714f9af5e1a1928/google_auth-1.7.1-py2.py3-none-any.whl (74kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 12.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.16.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (41.4.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (4.0)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.2.7)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.4.7)\n",
      "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2.21.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.0.4)\n",
      "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorboard 2.0.1 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.7.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tensorflow-estimator, google-auth, tensorboard, tensorflow-gpu\n",
      "  Found existing installation: tensorflow-estimator 1.15.1\n",
      "    Uninstalling tensorflow-estimator-1.15.1:\n",
      "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
      "  Found existing installation: google-auth 1.4.2\n",
      "    Uninstalling google-auth-1.4.2:\n",
      "      Successfully uninstalled google-auth-1.4.2\n",
      "  Found existing installation: tensorboard 1.15.0\n",
      "    Uninstalling tensorboard-1.15.0:\n",
      "      Successfully uninstalled tensorboard-1.15.0\n",
      "Successfully installed google-auth-1.7.1 tensorboard-2.0.1 tensorflow-estimator-2.0.1 tensorflow-gpu-2.0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "google",
         "tensorboard",
         "tensorflow",
         "tensorflow_core",
         "tensorflow_estimator"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 62
    },
    "colab_type": "code",
    "id": "ROEqCcyjk6gn",
    "outputId": "ef725053-f8b5-480d-cebe-75d6f76d6bc5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LmnEJIsWj20o",
    "outputId": "232d5a65-63d1-4ab4-c13c-86b6e1cff816"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at : /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at : {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z5rJZCDgn6X8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\t\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
    "            if verbose:\n",
    "                print('wa.s>',W_a_dot_s.shape)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>',U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        def create_inital_state(inputs, hidden_size):\n",
    "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
    "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
    "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
    "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
    "            return fake_state\n",
    "\n",
    "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
    "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YF1Z2XDIkyNJ"
   },
   "outputs": [],
   "source": [
    "#from attention import AttentionLayer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "a36VeGdh7ou8",
    "outputId": "0ad8d028-8a09-4364-d509-c6adc411bee8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-4cf15d31-63f3-4a71-b59f-f755364b114c\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-4cf15d31-63f3-4a71-b59f-f755364b114c\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Processed2.csv to Processed2.csv\n",
      "User uploaded file \"Processed2.csv\" with length 6904831 bytes\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "v-A1UxC32hlu",
    "outputId": "a6067e07-b090-4982-dea3-a528eacdf957"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import csv\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WM-LlDk-B2aO"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Processed2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "YEEIeMCPEcLJ",
    "outputId": "48d25651-4f50-4237-d936-b512f523c8b6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the daman and diu administration on wednesday withdrew circular that asked women staff to tie rakhis on male colleagues after the order triggered backlash from employees and was ripped apart on so...</td>\n",
       "      <td>sost daman diu revokes mandatory rakshabandhan in offices order eost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>from her special numbers to tvappearances bollywood actor malaika arora khan has managed to carve her own identity the actor who made her debut in the hindi film industry with the blockbuster debu...</td>\n",
       "      <td>sost malaika slams user who trolled her for divorcing rich man eost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the indira gandhi institute of medical sciences igims in patna amended its marital declaration form on thursday replacing the word virgin with unmarried after controversyuntil now new recruits to ...</td>\n",
       "      <td>sost virgin now corrected to unmarried in igims form eost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lashkaretaibas kashmir commander abu dujana was killed in an encounter in village in pulwama district of jammu and kashmir earlier this week dujana who had managed to give the security forces slip...</td>\n",
       "      <td>sost aaj aapne pakad liya let man dujana before being killed eost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hotels in mumbai and other indian cities are to train their staff to spot signs of sex trafficking such as frequent requests for bed linen changes or do not disturb sign left on the door for days ...</td>\n",
       "      <td>sost hotel staff to get training to spot signs of sex trafficking eost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                      text                                                                headline\n",
       "0  the daman and diu administration on wednesday withdrew circular that asked women staff to tie rakhis on male colleagues after the order triggered backlash from employees and was ripped apart on so...    sost daman diu revokes mandatory rakshabandhan in offices order eost\n",
       "1  from her special numbers to tvappearances bollywood actor malaika arora khan has managed to carve her own identity the actor who made her debut in the hindi film industry with the blockbuster debu...     sost malaika slams user who trolled her for divorcing rich man eost\n",
       "2  the indira gandhi institute of medical sciences igims in patna amended its marital declaration form on thursday replacing the word virgin with unmarried after controversyuntil now new recruits to ...               sost virgin now corrected to unmarried in igims form eost\n",
       "3  lashkaretaibas kashmir commander abu dujana was killed in an encounter in village in pulwama district of jammu and kashmir earlier this week dujana who had managed to give the security forces slip...       sost aaj aapne pakad liya let man dujana before being killed eost\n",
       "4  hotels in mumbai and other indian cities are to train their staff to spot signs of sex trafficking such as frequent requests for bed linen changes or do not disturb sign left on the door for days ...  sost hotel staff to get training to spot signs of sex trafficking eost"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H_oTcVGXV33G"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(df['text'],df['headline'],test_size=0.1, random_state = 0 , shuffle =True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d6it_5O8WJW3"
   },
   "outputs": [],
   "source": [
    "# Fixing max length of text and headline\n",
    "max_text_len=600\n",
    "max_headline_len=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "bgs4vv_OVsqT",
    "outputId": "8b93c71b-bc86-4e83-99de-b26490d265f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2709    in provocative remark that will only make the alreadyraging debate over cow slaughter and consumption of beef more heated sadhvi who attended meeting of several hindu outfits in panaji on wednesda...\n",
       "253     india captain virat kohli has said he is not affected by peoples opinions on his lack of form think people start counting the number of innings when batsman does not score welli was not looking at...\n",
       "3923    aaj tak live tv with live election results congratulate shri narendra modi and the bjp on their victory in uttar pradesh uttarakhandmy heartiest congratulations to capt amarinder singhji all our p...\n",
       "1495    australian hockey player tom craig intends to pay his university fees with earnings from the upcoming hockey indian league craig who was bought by the kalinga lancers for 67000 45 lakh said that a...\n",
       "3139    ever since the racial attack on africans in april in greater noida several such incidents have come to lightalso read attack on nigerian students in greater noida hundreds booked arrested in recen...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "C8SWQB8jWCul",
    "outputId": "f0d3d5bd-df19-432a-f2e2-e849d2e3d9f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 80.57225215781975\n",
      "Total Coverage of rare words: 7.879379013248801\n"
     ]
    }
   ],
   "source": [
    "# Building tokenizer to convert word sequence into integer sequence\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "\n",
    "# Analysing the number of rare words in the vocabulary (rule: any word that appears 3 or leass times is rare)\n",
    "\n",
    "thresh=6\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)\n",
    "\n",
    "#prepare a tokenizer for articles on training data\n",
    "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "IFJ7oAMuWGDi",
    "outputId": "057bf22b-c804-4464-a7bd-5528c49b946b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 55.37288539432929\n",
      "Total Coverage of rare words: 11.232750912298508\n"
     ]
    }
   ],
   "source": [
    "# Building tokenizer for headline as well as we did for text\n",
    "\n",
    "#prepare a tokenizer for headlines on training data\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "# Analysis for rare words in headlines (here threshold is 2 for rare words as the length of headlines is shorter.) \n",
    "\n",
    "thresh=2\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)\n",
    "\n",
    "#prepare a tokenizer for headlines on training data\n",
    "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_headline_len, padding='post')\n",
    "y_val   =   pad_sequences(y_val_seq, maxlen=max_headline_len, padding='post')\n",
    "\n",
    "#size of vocabulary\n",
    "y_voc  =   y_tokenizer.num_words +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9y794xDqWZHt"
   },
   "outputs": [],
   "source": [
    "# deleting the headlines that only have start and end tokens in them\n",
    "\n",
    "ind=[]\n",
    "for i in range(len(y_tr)):\n",
    "    cnt=0\n",
    "    for j in y_tr[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_tr=np.delete(y_tr,ind, axis=0)\n",
    "x_tr=np.delete(x_tr,ind, axis=0)\n",
    "\n",
    "ind=[]\n",
    "for i in range(len(y_val)):\n",
    "    cnt=0\n",
    "    for j in y_val[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_val=np.delete(y_val,ind, axis=0)\n",
    "x_val=np.delete(x_val,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gmUKmZ-DmsYX"
   },
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word\n",
    "reverse_source_word_index=x_tokenizer.index_word\n",
    "target_word_index=y_tokenizer.word_index\n",
    "\n",
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "      if((i!=0 and i!=target_word_index['sost']) and i!=target_word_index['eost']):\n",
    "        newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 826
    },
    "colab_type": "code",
    "id": "_I9GMTUOWcUG",
    "outputId": "8566d2e9-c27b-4b51-d5dd-1fef2606bd0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 600)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 600, 100)     1186300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   [(None, 600, 600), ( 962400      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    374700      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 600, 300), ( 1081200     bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 300),  481200      embedding_1[0][0]                \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 600)    0           lstm_2[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 3747)   2251947     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 6,518,047\n",
      "Trainable params: 6,518,047\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building model\n",
    "\n",
    "from tensorflow.keras import backend as K \n",
    "K.clear_session()\n",
    "\n",
    "latent_dim = 300\n",
    "embedding_dim=100\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#encoder lstm 1\n",
    "#encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "#encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#encoder lstm 1\n",
    "encoder_lstm1 = Bidirectional(LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4))\n",
    "encoder_output1, forward_state_h1, forward_state_c1, backward_state_h1, backward_state_c1 = encoder_lstm1(enc_emb)\n",
    "state_h1 = Concatenate()([forward_state_h1, backward_state_h1])\n",
    "state_c1 = Concatenate()([forward_state_c1, backward_state_c1])\n",
    "encoder_states1 = [state_h1, state_c1]\n",
    "\n",
    "#encoder lstm 2\n",
    "#encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "#encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encoder lstm 3\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output1)\n",
    "#encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "# Attention layer\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# Concat attention input and decoder LSTM output\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "# Define the model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "goa4O5puWgyT"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ZO3WRjqBWo3y",
    "outputId": "bec6cf4a-19ec-46ff-eb3e-404267f8688d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 3719 samples, validate on 413 samples\n",
      "Epoch 1/100\n",
      "3719/3719 [==============================] - 79s 21ms/sample - loss: 6.3260 - acc: 0.1809 - val_loss: 5.0311 - val_acc: 0.2789\n",
      "Epoch 2/100\n",
      "3719/3719 [==============================] - 65s 17ms/sample - loss: 5.5942 - acc: 0.2224 - val_loss: 4.8883 - val_acc: 0.3066\n",
      "Epoch 3/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 5.4587 - acc: 0.2437 - val_loss: 4.8832 - val_acc: 0.3462\n",
      "Epoch 4/100\n",
      "3719/3719 [==============================] - 65s 18ms/sample - loss: 5.3571 - acc: 0.2754 - val_loss: 4.7889 - val_acc: 0.3634\n",
      "Epoch 5/100\n",
      "3719/3719 [==============================] - 65s 18ms/sample - loss: 5.2802 - acc: 0.2984 - val_loss: 4.6631 - val_acc: 0.3691\n",
      "Epoch 6/100\n",
      "3719/3719 [==============================] - 65s 18ms/sample - loss: 5.2019 - acc: 0.3091 - val_loss: 4.6251 - val_acc: 0.3696\n",
      "Epoch 7/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 5.1587 - acc: 0.3098 - val_loss: 4.6749 - val_acc: 0.3603\n",
      "Epoch 8/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 5.1209 - acc: 0.3111 - val_loss: 4.5880 - val_acc: 0.3702\n",
      "Epoch 9/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 5.0713 - acc: 0.3112 - val_loss: 4.6597 - val_acc: 0.3597\n",
      "Epoch 10/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 5.0199 - acc: 0.3129 - val_loss: 4.5632 - val_acc: 0.3691\n",
      "Epoch 11/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 4.9595 - acc: 0.3133 - val_loss: 4.5682 - val_acc: 0.3705\n",
      "Epoch 12/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 4.9187 - acc: 0.3146 - val_loss: 4.5404 - val_acc: 0.3707\n",
      "Epoch 13/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 4.8661 - acc: 0.3153 - val_loss: 4.5372 - val_acc: 0.3698\n",
      "Epoch 14/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 4.8244 - acc: 0.3156 - val_loss: 4.5176 - val_acc: 0.3652\n",
      "Epoch 15/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 4.7836 - acc: 0.3154 - val_loss: 4.5314 - val_acc: 0.3700\n",
      "Epoch 16/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 4.7400 - acc: 0.3168 - val_loss: 4.5039 - val_acc: 0.3694\n",
      "Epoch 17/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 4.6939 - acc: 0.3169 - val_loss: 4.5322 - val_acc: 0.3608\n",
      "Epoch 18/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 4.6528 - acc: 0.3175 - val_loss: 4.5167 - val_acc: 0.3672\n",
      "Epoch 19/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 4.6069 - acc: 0.3174 - val_loss: 4.5198 - val_acc: 0.3722\n",
      "Epoch 20/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 4.5695 - acc: 0.3178 - val_loss: 4.5251 - val_acc: 0.3661\n",
      "Epoch 21/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 4.5247 - acc: 0.3191 - val_loss: 4.5342 - val_acc: 0.3652\n",
      "Epoch 22/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 4.4954 - acc: 0.3189 - val_loss: 4.5002 - val_acc: 0.3753\n",
      "Epoch 23/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 4.4529 - acc: 0.3207 - val_loss: 4.5476 - val_acc: 0.3584\n",
      "Epoch 24/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 4.4172 - acc: 0.3214 - val_loss: 4.5254 - val_acc: 0.3716\n",
      "Epoch 25/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 4.3792 - acc: 0.3209 - val_loss: 4.5393 - val_acc: 0.3718\n",
      "Epoch 26/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 4.3438 - acc: 0.3230 - val_loss: 4.5510 - val_acc: 0.3674\n",
      "Epoch 27/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 4.2970 - acc: 0.3220 - val_loss: 4.5482 - val_acc: 0.3760\n",
      "Epoch 28/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 4.2756 - acc: 0.3240 - val_loss: 4.5531 - val_acc: 0.3685\n",
      "Epoch 29/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 4.2336 - acc: 0.3237 - val_loss: 4.5568 - val_acc: 0.3685\n",
      "Epoch 30/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 4.1935 - acc: 0.3268 - val_loss: 4.5793 - val_acc: 0.3707\n",
      "Epoch 31/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 4.1590 - acc: 0.3265 - val_loss: 4.5990 - val_acc: 0.3641\n",
      "Epoch 32/100\n",
      "3719/3719 [==============================] - 68s 18ms/sample - loss: 4.1147 - acc: 0.3279 - val_loss: 4.6045 - val_acc: 0.3746\n",
      "Epoch 33/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 4.0907 - acc: 0.3286 - val_loss: 4.6072 - val_acc: 0.3705\n",
      "Epoch 34/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 4.0354 - acc: 0.3299 - val_loss: 4.6181 - val_acc: 0.3740\n",
      "Epoch 35/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 3.9883 - acc: 0.3327 - val_loss: 4.6439 - val_acc: 0.3729\n",
      "Epoch 36/100\n",
      "3719/3719 [==============================] - 68s 18ms/sample - loss: 3.9671 - acc: 0.3324 - val_loss: 4.6419 - val_acc: 0.3735\n",
      "Epoch 37/100\n",
      "3719/3719 [==============================] - 68s 18ms/sample - loss: 3.9194 - acc: 0.3355 - val_loss: 4.6932 - val_acc: 0.3713\n",
      "Epoch 38/100\n",
      "3719/3719 [==============================] - 68s 18ms/sample - loss: 3.8707 - acc: 0.3368 - val_loss: 4.6689 - val_acc: 0.3713\n",
      "Epoch 39/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 3.8271 - acc: 0.3390 - val_loss: 4.6628 - val_acc: 0.3724\n",
      "Epoch 40/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 3.7864 - acc: 0.3416 - val_loss: 4.6978 - val_acc: 0.3669\n",
      "Epoch 41/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 3.7515 - acc: 0.3430 - val_loss: 4.6897 - val_acc: 0.3709\n",
      "Epoch 42/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 3.7178 - acc: 0.3439 - val_loss: 4.7212 - val_acc: 0.3702\n",
      "Epoch 43/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 3.6724 - acc: 0.3474 - val_loss: 4.7236 - val_acc: 0.3744\n",
      "Epoch 44/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 3.6371 - acc: 0.3490 - val_loss: 4.7350 - val_acc: 0.3669\n",
      "Epoch 45/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 3.5940 - acc: 0.3530 - val_loss: 4.7604 - val_acc: 0.3749\n",
      "Epoch 46/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 3.5573 - acc: 0.3546 - val_loss: 4.7581 - val_acc: 0.3689\n",
      "Epoch 47/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 3.5143 - acc: 0.3602 - val_loss: 4.8053 - val_acc: 0.3614\n",
      "Epoch 48/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 3.4727 - acc: 0.3615 - val_loss: 4.8303 - val_acc: 0.3641\n",
      "Epoch 49/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 3.4352 - acc: 0.3654 - val_loss: 4.8093 - val_acc: 0.3652\n",
      "Epoch 50/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 3.4014 - acc: 0.3695 - val_loss: 4.8253 - val_acc: 0.3709\n",
      "Epoch 51/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 3.3480 - acc: 0.3743 - val_loss: 4.8361 - val_acc: 0.3689\n",
      "Epoch 52/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 3.3224 - acc: 0.3778 - val_loss: 4.8580 - val_acc: 0.3654\n",
      "Epoch 53/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 3.2713 - acc: 0.3825 - val_loss: 4.8626 - val_acc: 0.3705\n",
      "Epoch 54/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 3.2461 - acc: 0.3867 - val_loss: 4.8869 - val_acc: 0.3709\n",
      "Epoch 55/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 3.1965 - acc: 0.3917 - val_loss: 4.9201 - val_acc: 0.3625\n",
      "Epoch 56/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 3.1557 - acc: 0.3955 - val_loss: 4.9067 - val_acc: 0.3705\n",
      "Epoch 57/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 3.1229 - acc: 0.4016 - val_loss: 4.9609 - val_acc: 0.3551\n",
      "Epoch 58/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 3.0762 - acc: 0.4084 - val_loss: 4.9445 - val_acc: 0.3652\n",
      "Epoch 59/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 3.0463 - acc: 0.4112 - val_loss: 4.9437 - val_acc: 0.3656\n",
      "Epoch 60/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 3.0041 - acc: 0.4169 - val_loss: 4.9548 - val_acc: 0.3617\n",
      "Epoch 61/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 2.9709 - acc: 0.4219 - val_loss: 4.9910 - val_acc: 0.3667\n",
      "Epoch 62/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 2.9331 - acc: 0.4288 - val_loss: 4.9957 - val_acc: 0.3614\n",
      "Epoch 63/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 2.8803 - acc: 0.4338 - val_loss: 4.9966 - val_acc: 0.3628\n",
      "Epoch 64/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 2.8535 - acc: 0.4378 - val_loss: 5.0167 - val_acc: 0.3586\n",
      "Epoch 65/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 2.8080 - acc: 0.4481 - val_loss: 5.0317 - val_acc: 0.3654\n",
      "Epoch 66/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 2.7783 - acc: 0.4507 - val_loss: 5.0400 - val_acc: 0.3663\n",
      "Epoch 67/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 2.7307 - acc: 0.4576 - val_loss: 5.0558 - val_acc: 0.3639\n",
      "Epoch 68/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 2.7186 - acc: 0.4611 - val_loss: 5.0721 - val_acc: 0.3621\n",
      "Epoch 69/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 2.6804 - acc: 0.4667 - val_loss: 5.0716 - val_acc: 0.3669\n",
      "Epoch 70/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 2.6334 - acc: 0.4735 - val_loss: 5.0987 - val_acc: 0.3608\n",
      "Epoch 71/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 2.6040 - acc: 0.4786 - val_loss: 5.1173 - val_acc: 0.3630\n",
      "Epoch 72/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 2.5645 - acc: 0.4849 - val_loss: 5.1262 - val_acc: 0.3573\n",
      "Epoch 73/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 2.5240 - acc: 0.4931 - val_loss: 5.1041 - val_acc: 0.3667\n",
      "Epoch 74/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 2.5081 - acc: 0.4947 - val_loss: 5.1355 - val_acc: 0.3579\n",
      "Epoch 75/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 2.4672 - acc: 0.5027 - val_loss: 5.1518 - val_acc: 0.3641\n",
      "Epoch 76/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 2.4188 - acc: 0.5113 - val_loss: 5.1779 - val_acc: 0.3557\n",
      "Epoch 77/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 2.4053 - acc: 0.5129 - val_loss: 5.1529 - val_acc: 0.3619\n",
      "Epoch 78/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 2.3580 - acc: 0.5199 - val_loss: 5.1753 - val_acc: 0.3603\n",
      "Epoch 79/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 2.3379 - acc: 0.5254 - val_loss: 5.1680 - val_acc: 0.3652\n",
      "Epoch 80/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 2.2861 - acc: 0.5335 - val_loss: 5.2019 - val_acc: 0.3573\n",
      "Epoch 81/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 2.2901 - acc: 0.5339 - val_loss: 5.2101 - val_acc: 0.3665\n",
      "Epoch 82/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 2.2246 - acc: 0.5445 - val_loss: 5.2609 - val_acc: 0.3524\n",
      "Epoch 83/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 2.2055 - acc: 0.5491 - val_loss: 5.2421 - val_acc: 0.3564\n",
      "Epoch 84/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 2.1689 - acc: 0.5569 - val_loss: 5.2363 - val_acc: 0.3661\n",
      "Epoch 85/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 2.1536 - acc: 0.5573 - val_loss: 5.2741 - val_acc: 0.3546\n",
      "Epoch 86/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 2.1244 - acc: 0.5643 - val_loss: 5.2584 - val_acc: 0.3603\n",
      "Epoch 87/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 2.0795 - acc: 0.5718 - val_loss: 5.2607 - val_acc: 0.3650\n",
      "Epoch 88/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 2.0609 - acc: 0.5759 - val_loss: 5.3330 - val_acc: 0.3517\n",
      "Epoch 89/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 2.0419 - acc: 0.5797 - val_loss: 5.3004 - val_acc: 0.3573\n",
      "Epoch 90/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 2.0004 - acc: 0.5883 - val_loss: 5.3255 - val_acc: 0.3619\n",
      "Epoch 91/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 1.9678 - acc: 0.5928 - val_loss: 5.3250 - val_acc: 0.3573\n",
      "Epoch 92/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 1.9441 - acc: 0.5974 - val_loss: 5.3241 - val_acc: 0.3564\n",
      "Epoch 93/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 1.9270 - acc: 0.6029 - val_loss: 5.3529 - val_acc: 0.3544\n",
      "Epoch 94/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 1.8914 - acc: 0.6089 - val_loss: 5.3643 - val_acc: 0.3650\n",
      "Epoch 95/100\n",
      "3719/3719 [==============================] - 67s 18ms/sample - loss: 1.8752 - acc: 0.6106 - val_loss: 5.3505 - val_acc: 0.3658\n",
      "Epoch 96/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 1.8509 - acc: 0.6142 - val_loss: 5.3747 - val_acc: 0.3586\n",
      "Epoch 97/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 1.8058 - acc: 0.6252 - val_loss: 5.3778 - val_acc: 0.3632\n",
      "Epoch 98/100\n",
      "3719/3719 [==============================] - 66s 18ms/sample - loss: 1.7871 - acc: 0.6276 - val_loss: 5.4139 - val_acc: 0.3533\n",
      "Epoch 99/100\n",
      "3719/3719 [==============================] - 65s 18ms/sample - loss: 1.7579 - acc: 0.6366 - val_loss: 5.4079 - val_acc: 0.3599\n",
      "Epoch 100/100\n",
      "3719/3719 [==============================] - 65s 18ms/sample - loss: 1.7358 - acc: 0.6402 - val_loss: 5.4211 - val_acc: 0.3575\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=100, batch_size=256, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "1Cre3vVo6xGo",
    "outputId": "d293a955-c7e8-4da0-e6a9-0c81bfd53c4f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rmOsxoY7zvew"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive \n",
    "from google.colab import auth \n",
    "from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tz1PAgXd_Msr"
   },
   "outputs": [],
   "source": [
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()                       \n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cgHZ_YHI_M9c"
   },
   "outputs": [],
   "source": [
    "model.save('Abstraction_model_1.h5')\n",
    "model_file = drive.CreateFile({'title' : 'Abstraction_model_1.h5'})                       \n",
    "model_file.SetContentFile('Abstraction_model_1.h5')                       \n",
    "model_file.Upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g7xBWymzYSAi"
   },
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the feature vector\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-yANb7XUYYt6"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['sost']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "      \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        \n",
    "        if(sampled_token!='eost'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == 'eost'  or len(decoded_sentence.split()) >= (max_headline_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "colab_type": "code",
    "id": "y27BoEv0ZL_1",
    "outputId": "1815d4f9-a261-454e-f69e-83bcef0469b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article: in provocative remark that will only make the debate over cow slaughter and consumption of beef more heated sadhvi who attended meeting of several hindu outfits in panaji on wednesday triggered fresh row by saying that those who considered eating beef as status symbol should be hanged this remark by sadhvi saraswati who hails from madhya pradesh sharp reaction from the congress which said that her speech would communal hatred and demanded that the bjpled government in goa lodge an fir against appeal to the government of india that those people who consider eating meat of their own mother as status symbol should be hanged saraswati had those who eat beef should be brought before the public and hanged then only people will know that it is our duty to protect gau she said while commenting on beef consumption during the inauguration of the all india hindu convention at village in must keep arms in homes to protect saraswati president of the dharma seva samiti of in madhya pradesh also asked the hindus to keep arms in their homes to protect we do not stock arms we will be destroyed in the future she bharat is under attack from all directions efforts are being made to separate kashmir from bharat and also stop the amarnath pilgrimage and are being she out at some political parties for their demand to ban outfits calling for the creation of the hindu rashtra she said that they should realise that no power in the country could prevent hindus from establishing the hindu said there is no such thing as saffron terrorism saffron means life dedicated to the nation and dharma nearly 130 hindu organisations from 21 states and countries including bangladesh sri lanka and nepal are attending the fourday convention its organisers said congress slams goa silence over to the speeches made at the meet all india congress committee secretary girish questioned why the manohar state government was silent over the provoking communal hatred were made during the convention the state government has become party to the entire programme by maintaining silence over the matter and allowing it to continue also questioned goa forward party leader silence on the whose party is now an ally of the ruling bjp had in the past slammed the claim that it would ban beef in the state he had said that those who were trying to create communal would be dealt with strongly said why is he sardesai silent over statement promoting violence said the government should have taken suo cognisance of the comments and filed an fir against her for hate read supreme court notice to centre on plea challenging cattle slaughter ban \n",
      "Original headline: hang those who eat beef as status sadhvi \n",
      "Predicted headline:  hang birth to be declared at army zoo\n",
      "\n",
      "\n",
      "article: india captain virat kohli has said he is not affected by peoples opinions on his lack of form think people start counting the number of innings when batsman does not score was not looking at how many innings have not you are playing all formats you are not thinking which format you have not scored runs said kohli \n",
      "Original headline: people count my dont says virat kohli \n",
      "Predicted headline:  virat kohli is doubles during ex johnson\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,2):\n",
    "    print(\"article:\",seq2text(x_tr[i]))\n",
    "    print(\"Original headline:\",seq2summary(y_tr[i]))\n",
    "    print(\"Predicted headline:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "F_wakkROZgnE",
    "outputId": "834a030b-a8db-414a-e0fe-eedcb5b465b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article: prime minister narendra modis stern warning to selfproclaimed cow vigilantes seems to have fallen on deaf ears as group of men attacked truck drivers transporting cows in guwahati the incident took place on sunday july according to reports group of cow vigilantes stopped three vehicles transporting cows and beat up the drivers on the outskirts of guwahati the incident took place near some 30 km from capital guwahati the vehicles were coming from in upper assam when the members of the hindu yuva unit stopped them and asked the drivers to step out the men then brutally thrashed the drivers accusing them of cow hindu yuva parishad leader said these people smuggle cattle across the border to bangladesh they transport them in conditions we caught them red handed yesterday in one vehicle they pack 40 50 where there is space for only ten animals we found some of the animals had their limbs fractured but police remain blind to their plight and take bribe from these traders we confiscated the vehicle and reported it to police but cops came two hours late meanwhile assam police director general mukesh assured that probe was being conducted into sundays incident and the perpetrators will not be spared however the dgp also admitted that it was not possible for the police to prove adequate security to all cattle traders across the state and will be dealt with case to case basis not acceptable prime minister narendra modi had last week said that killing of people in the name of cow protection is not acceptable pm modis remarks came amid spurt of attacks by cow vigilantes and wave of speech to mark the centenary of the ashram in ahmedabad and birth anniversary of guru to mahatma gandhi modi said violence against others went against the ideals of the father of the people in the name of gau is not acceptable this is not something mahatma gandhi would approve he all work together let us create the india of mahatma gandhis dreams let us create an india our freedom fighters would be proud of the prime minister saidno person in this nation has the right to take the law in his or her own hands he saidthe prime ministers remarks came against the backdrop of growing incidents of cow vigilantism muslim youth was last week killed on board train by people who his family and repeatedly called them and beef never has and never will solve any problem as society there is no place for violence modi saidlast week thousands of people across the country took to the streets in citizens protest named not in my name against the recent incidents of mob inputs from also pm narendra modi ripped into cow of cow vigilantes it is time pm modi acted against them \n",
      "Original headline: cow vigilantes attack drivers transporting cattle in assam \n",
      "Predicted headline:  delhi govt to get fresh trains for\n",
      "\n",
      "\n",
      "article: rizvi education society which manages seven institutes including schools and colleges recently implemented the first phase of digital transformation of its education and administration system the institutes now have teaching interface in all biometric entry for students admissions and mobile for better interaction the education society also plans to introduce online assessment of all examinations admissions have not only reduced the work of our staff but have also made the process very transparent for everybody parents are also happy as they get daily updates about their childs attendance in college without even having to visit the institute said rizvi president rizvi education society the society spent around rs1 crore and took seven months to implement the first added that in the second phase the education society plans to start online assessment of exam papers and make study material available online for all its 6000 school and college management trained its teachers in collaboration with technology provider to ensure the final implementation is also cctv cameras were installed in all its institutes and all laboratories were equipped with latest technology our attempt to almost all our academic functions right from admissions to the generation of results has been very fruitful we intend to the infrastructure administration as well as process to ensure 360 degree effort said rizvi director rizvi education society \n",
      "Original headline: mumbai education society schools and colleges \n",
      "Predicted headline:  delhi govt to get machines for raping hrs to\n",
      "\n",
      "\n",
      "article: in startling twist to the estate murder mystery today the police discovered that three with documents of jayalalithaas property worth crores were stolen from the to worth hundreds of crores were taken from the estate some were in the name of sasikala and jayalalithaa jointly reportedly the mastermind of the heist was close to both jayalalithaa and sasikala on the other hand two main accused in the case met with separate accidents of the accused former employee at poes garden died in car crash in tamil nadus district while his close aide and the second accused met with car accident in keralas district was traveling with his wife and daughter who died in the simultaneous development based on the inputs from krishna bahadur the other security guard who was injured in the estate attack police have released of one of the comes day after the tamil nadu police claimed to have solved the murder mystery naming hawala operator and an at estate for conspiring the worked as driver for four years at jayalalithaas poes garden residence in chennai alias shyam was the owner of in leaders from opposition parties are raising questions on the mysterious spokesperson said the documents worth hundred crores have gone missing something mysterious was going on in jayalalithaas house and people surrounding her something to do with properties purchased illegally we need proper investigation into this \n",
      "Original headline: property papers worth from jayas bungalow \n",
      "Predicted headline:  sc orders off for strikes in lucknow\n",
      "\n",
      "\n",
      "article: more than 900 petroleum gas lpg cylinders stored in two trucks exploded on sunday near in district the incident which reportedly took place due to battery short circuit two trucks and vehicle while properties worth around 70 lakh were in the fire no casualties have been reported so far \n",
      "Original headline: over 900 lpg cylinders in karnataka \n",
      "Predicted headline:  delhi metro to get machines for boys in karnataka\n",
      "\n",
      "\n",
      "article: politicians cannot seem to keen off the headlines especially for all the wrong reasons case of obscene messages circulated by member of the legislative council from has whatsapp groups of the media in were in for shock when they suddenly found file in their with 56 photos of porn photographs were sent by the pictures and the message went viral and as soon as the realised that he was in the he switched off his phone and remained he is said to have apologised to the media saying he had sent it by this incident is reminder of the number of times karnataka has been caught in porn controversies and how the politicians of the state have been involved in them \n",
      "Original headline: ktaka bjp mlc sends porn stars pics to media on whatsapp \n",
      "Predicted headline:  what guj will be out in india case sc\n",
      "\n",
      "\n",
      "article: selfie guwahati feb 13 pti assam additional advocate general has been barred from entering the assembly for two weeks for allegedly clicking and uploading selfie on social media when the house was in session have received written complaint from mla hafiz bashir ahmed regarding the incident have forwarded the matter to the privilege committee assam speaker nath goswami said in the house informing that the panel has been asked to submit report within two weeks following an enquiry into the matter he said till the enquiry is over advise not to come to the assembly \n",
      "Original headline: assam law officer barred from assembly for taking selfie \n",
      "Predicted headline:  assam means unmarried nothing for 1st time in assam\n",
      "\n",
      "\n",
      "article: dehradun dec 18 pti special break will be given to the government employees from the muslim community in uttarakhand for friday prayers official sources said cabinet meeting yesterday chaired by chief minister harish rawat decided that special break from pm till 200 pm will be given to the employees from the community they said \n",
      "Original headline: muslim govt staff to get break for friday prayers \n",
      "Predicted headline:  suspicious of suspicious deposits worth lakh tax in mumbai\n",
      "\n",
      "\n",
      "article: married at 13 and three weeks pregnant minor girl rescued by the police has refused to go to her parents and expressed willingness to return to her husband and alleged rapist 22yearold man currently in jail the young man is behind bars as according to indian laws he married minor and allegedly forced her into physical relationship getting her pregnant the young womans father had filed complaint of abduction on may 10 when the minor girl left home to buy icecream for her family when they surrendered before city court judge last week she was three weeks pregnant case of rape was then filed against the man read how delhi man searched for his missing 13yearold daughter for two said they are clueless about their further course of action because the minor girl has refused to return to her parents and wants to be together with the alleged 22yearold khan who worked as cook told the police that he had married the girl following which he was booked under the child marriage act the police have also nabbed two of khans friends who acted as witnesses to the marriage the marriage has no validity said romil dcp girl is currently under the care of the children welfare committee which will also take call on the future of her pregnancy the girl lived with her parents and two younger brothers in single room accommodation in south east delhi the accused khan lived with his group of friends in the same neighbourhood \n",
      "Original headline: abducted raped wants to return to her husband \n",
      "Predicted headline:  mumbai police may become largest child\n",
      "\n",
      "\n",
      "article: london aug pti renowned harry potter author has apologised for wrongly accusing us president donald trump of refusing to shake the hand of disabled child during an event the british best known as the author of the harry potter fantasy series said yesterday that she deleted her july 28 tweets after she was informed that they were not full or accurate representation of what had happened at last mondays health care event at the white house came under fire for series of tweets in which she slammed trump for to ignore hand how stunning and how horrible that trump cannot bring himself to shake the hand of small boy who only wanted to touch the president the author had said but kelly mother of said interpretation of the clip was wrong re my tweets about the small boy in wheelchair whose hand the president appeared to ignore in press footage multiple sources have informed me that that was not full or accurate representation of their interaction tweeted very clearly projected my own around the issue of disabled people being overlooked or ignored onto the images saw and if that caused any distress to that boy or his family apologise she wrote trump is said to have shaken the boys hand as the president entered the room the bbc reported if someone can please get message to jk trump didnt my son wasnt even trying to shake his hand kelly wrote on facebook \n",
      "Original headline: jk apologises for tweets against donald trump \n",
      "Predicted headline:  pm modi honours boys to be redeveloped\n",
      "\n",
      "\n",
      "article: as part of the film promotion picture of tied on bed went viral on the internet with the hashtag got kidnapped however the actor was quick enough to clarify that it was for her upcoming absolutely fine thank for ur part of our movie promotion announcement at took to twitter to share the controversial the picture was used as to attract audience twitterati have slammed the actor for her promotional this shows how nobody if someone got kidnapped they will make memes and abuse the victim for 18 is sweet it is you cannot take followers concerns granted am sorry am this movie 18 18 getting kidnapped this will go down as one of the worst promotional tactics ever for film 18 2017 so much for all the female empowerment talks promotions unless it actually happened april 18 now they have used actress kidnapped as promotion will they rape next 18 2017 later clarified that was not aware of surprise to for her movie was not aware of is well and always well for is in new delhi to represent her save shakti campaign to the law minister was not aware of this promotion as am in delhi representing my save shakti petition to the law for the to this made headlines when she exposed the ugly reality of casting couch in february in fact her save shakti campaign aims to protect female artists in the entertainment is the daughter of noted tamil actor she made her acting debut in 2012 and shot to fame after her stellar performance in 2016 last seen in megastar is playing pivotal role in the tamil film vikram which also stars and vijay in the read baahubali an emotional ss rajamouli bids farewell to team on twitter \n",
      "Original headline: promotional pic actress slammed online \n",
      "Predicted headline:  promotional actress slammed for guru\n",
      "\n",
      "\n",
      "article: an indianorigin man was shot at in atlanta united states the victim identified as sameer patel was shot in the head and his condition is stated to be critical patel was working in department store two unidentified persons barged into the store and opened fire at attacking patel the duo stole cash box and fled from the spotthe entire incident was caught on camera family has been sent copy of the cctv is native of gujarats indian killed in us businessman patel shot dead near his home \n",
      "Original headline: indianorigin man shot dead at store in atlanta \n",
      "Predicted headline:  delhi man beaten to stop geeta married\n",
      "\n",
      "\n",
      "article: archaeologists have unearthed large statue that is believed to have once stood guard over an ancient hospital at famed angkor temple nearly two metre tall carving which is thought to be from the late 12th to the early 13th century was discovered during dig on saturday said long spokesman for authority the state agency charged with managing the complex the angkor park world heritage site contains the remains of the different capitals of the empire dating from the to the 15th and is most popular tourist the height of its power the city and its hundreds of temples boasted more than million inhabitants making it one of the worlds most populous centres huge of the park have been over the decades creating archaeological wonder that more than two million visitors year but the complex remains treasure for yet to be discovered finds cambodian archaeologists and experts from institute of southeast asian studies found the statue buried 40 under the ground during an of an hospital built during the of king agency said the arms and legs had broken off but the carving on the body and head remain beautiful despite the passage of time they said the statue was likely to have been symbolic guardian of the hospital \n",
      "Original headline: statue unearthed at temple complex \n",
      "Predicted headline:  statue unearthed at temple complex\n",
      "\n",
      "\n",
      "article: indian shuttler hs prannoy clinched the us open grand prix gold tournament after defeating compatriot parupalli kashyap in the final on sundaythe old prannoy showed great determination to clinch his third grand prix gold and maiden us open title as he defeated kashyap 2115 2022 in had found place in the final after defeating while kashyap korean in the emerges from epic to win british open looked quite impressive from the start as he clinched the first game after going 48 down early on the indian shuttler showed excellent court coverage and he looked quite comfortable against his much experienced the former commonwealth games gold medallist parupalli kashyap fought back in the second game he executed his and was able to take the match to the after winning the second game in the third set it was all prannoy as the youngster gave no chance to kashyap and raced to victory with the reading wins his fourth tour de has been good year for the indian badminton players as last month srikanth created history by becoming the first indian to win two successive titles and by entering three consecutive finals at the open singapore open and the australian open \n",
      "Original headline: prannoy beats kashyap in allindia final to win \n",
      "Predicted headline:  kashyap prannoy enter us open semifinals\n",
      "\n",
      "\n",
      "article: new delhi aug pti successive governments have short changed air india by treating it like their private properties tmc leader dinesh said today as he urged the centre to review the decision to stake in the airline by just looking at the debt and ignoring the revival signs would be to take narrow view of the situation the former railway minister said as part of efforts to revive the national carrier the cabinet has given inprinciple approval for and the final are being worked out by group of ministers if air india today is in this financial situation it was not because of air india but successive governments have air india and treated it like their private properties and at times private airlines be international or domestic came under category of favoured airlines told pti against this backdrop said it is evident that there is potential for further growth of air india if the plan continues along with other measures \n",
      "Original headline: air india tmc leader \n",
      "Predicted headline:  air india to serve wine for\n",
      "\n",
      "\n",
      "article: indias elite counterterrorism force the national security guard nsg today made its debut at the republic day parade in new contingent of some 60 commandos in their black and gear marched on the giving salute to president pranab other commandos were on seven vehicles with mounted on them \n",
      "Original headline: nsg debut at republic day parade \n",
      "Predicted headline:  nsg debut debut debut debut in republic case\n",
      "\n",
      "\n",
      "article: by chakraborty new delhi jul 24 pti aadar jains entry in bollywood comes at time when the nepotism debate has gained momentum but the newcomer says he would like people to not judge him before seeing his work aadar the grandson of raj kapoor will make his debut with band and his launch event was hosted by his cousin ranbir kapoor in an interview with pti the actor says he is aware of the debate around nepotism and the negative comments his launch attracted as newcomer who has always dreamt of becoming an actor it was huge deal for me to be introduced like that read the comments after the launch about nepotism when you work so hard give it all an entire year of blood sweat and hard work and then you read about these comments you feel bad am human after all aadar says but the 23yearold actor does not want to get into the debate of whether he is talented or not dont want to say anything yes feel bad when people says things without seeing my work want my work to speak for itself thats the only thing am here for however aadar does have an opinion about nepotism in the film industry the youngster says someone belonging to film family does get an easy opportunity to meet director or casting director but it does not guarantee movie as an actor can only go forward on the basis of merit the industry believes in talent it doesnt matter what background you are from you might be an outsider or from film family what matters is your talent had to audition for the film might come from film family but that didnt guarantee me anything at the end of the day dont think writer director or producer will invest in person who does not have the talent on the contrary aadar feels actors who hail from film families have to deal with the burden of expectations yash raj films band has been directed by faisal and will also serve as the for another newcomer singh the film is about seven who form musical band in the prison the movie is from the usual debut which often opt for but aadar says he didnt think of it like that when he signed the project had not thought about it as an film and thats why did it this is kind of film that would like to watch it is new and story not told before on his role as prison inmate aadar says he had no real understanding of how to go about the role as his only references have been movies and tv shows like and prison break didnt know what actually happens inside prison that was very interesting for me especially the situation that fascinated me those are the reasons why wanted to do the film band releases on august 25 elder brother jain made his debut in 2014 with hum dil which was box office the actor says has not taken beating and will soon announce his second bollywood venture \n",
      "Original headline: felt bad am human after all on nepotism remarks \n",
      "Predicted headline:  felt bad not human human all in future akshay\n",
      "\n",
      "\n",
      "article: shahid kapoor and mira rajput are their daughter pretty soon it seems the new parents are way too excited about and want to experience double the joy with another was just yesterday that shahid kapoor shared the first proper photo of with her mother mira and his lost their heart to the little one now they need to make way for younger to magazine shahid opened up on his and family plans mira who is just 22 would prefer to have second kid soon as well she wants to the norm get the kids to certain age and then be free to do what she likes also see shahid kapoor shares photo with daughter also revealed that his child was not planned but mira was happy and ready about it he said it was not planned actually but think we were ready for it was to get married and have family my job is lonely one was lonely for three or four kapoor and mira rajput tied the knot in 2015 mira who was pursuing her when she met shahid wants to have another child now \n",
      "Original headline: wants to have second child soon shahid kapoor \n",
      "Predicted headline:  shahid has not apply for nominations of iifa show\n",
      "\n",
      "\n",
      "article: the police on wednesday arrested two who were performing stunts at mumbais marine drive to impress two arrested accused khan 18 and khan 18 are residents of and police inspector from marine drive police station said we got an information that four riders are performing stunts at the sea face they were not just their own lives but were posing threat to those sitting at marine drive too we did near islam and caught two of themthe other two managed to flee leaving their bikes at the spotthe police registered four different cases in their statement to police and claimed they were inspired by the movie and were performing stunts to impress girls at the have been booked under sections rash driving or riding on public way and act endangering life or personal safety of others of the indian penal code the two arrested accused were released on bail while the hunt for two others is more \n",
      "Original headline: arrested for inspired stunts in mumbai \n",
      "Predicted headline:  man arrested for for pm modi on remarks\n",
      "\n",
      "\n",
      "article: by lalit jha washington jul 18 pti the islamic state isisk has lost its hold in afghanistan days after the terror groups head abu was killed by us troops in an the pentagon has said the pentagon now estimates that isisk in afghanistan numbers somewhere in the hundreds we dont think its over 1000 they hold no territory in province there are certainly fighters there but theyre mostly spending their time trying to stay alive said pentagon spokesman navy capt jeff davis during an news conference yesterday davis said the killing of isisk leader abu in drone strike last week disrupted it is expansion plans his death will further disrupt the groups plans to expand its operations in afghanistan he said adding that this is the third time in the past year that us forces in afghanistan have killed sitting leader of isisk killed in strike on july 11 in abu syed was the overall isisk amir in afghanistan for only six weeks issuing operational guidance financial management and acting as the primary for operations with isis throughout afghanistan he said his death comes not long after that of his predecessor sheikh abdul who was killed by us forces in raid on april 26 in province as part of ongoing efforts to defeat isisk in afghanistan he added isis threatens america and the west because of its commitment to plot direct and inspire terrorist attacks and its ability to recruit move and finance the terrorists who commit these attacks he said adding that the terrorists have been very clear in their propaganda magazine and other that they want to recruit and attack globally isisk called was formed in january 2015 as group of several islamic extremist organizations organized and committed to supporting the radical ideals of the islamic state davis said adding that isisk is committed to establishing an afghan presence on behalf of isis and isis caliphate to the abolition of traditionally recognised sovereign borders \n",
      "Original headline: isis on back foot in afghanistan post leaders death us \n",
      "Predicted headline:  isis failed in india despite large muslim population\n",
      "\n",
      "\n",
      "article: jimmy kimmel has opened up about his newborn sons surgery and pleaded for people to support the affordable care act also known as in an emotional on his tv was scary story and before go into it want you to know it has happy ending the talk show host told the audience of jimmy kimmel obama took to social media kimmel and the benefits of the affordable care act well said jimmy that is exactly why we fought so hard for the aca and why we need to protect it for kids like and congratulations he tweeted kimmel described how william john was born 10 days ago with heart defect the condition was discovered hours after the comedians wife gave was taken by ambulance to the childrens hospital of los angeles to undergo surgery kimmel described it as the longest three hours of my was released from hospital six days after the surgery and was doing great kimmel said he showed photos of him with his wife their daughter two and infant will have another operation within six months to repair the followed by third procedure when he is host then delivered an speech on how every american family should be able to receive healthcare no parent should ever have to decide if they can afford to save their childs life kimmel told viewers he criticised president donald trumps proposed cuts to the national institutes of health and praised congress for instead calling for increased your baby is going to die and it doesnt have to it shouldnt matter how much money you make whether youre republican or or something else we all agree on that right he said he would skip the rest of this weeks shows to be with his family \n",
      "Original headline: jimmy talks about his newborn \n",
      "Predicted headline:  jimmy talks about his newborn\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(30,50):\n",
    "    print(\"article:\",seq2text(x_tr[i]))\n",
    "    print(\"Original headline:\",seq2summary(y_tr[i]))\n",
    "    print(\"Predicted headline:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wz8khhbScFRE"
   },
   "outputs": [],
   "source": [
    "original = []\n",
    "predicted = []\n",
    "for i in range(len(x_val)):\n",
    "  original.append(seq2summary(y_val[i]))\n",
    "  predicted.append(decode_sequence(x_val[i].reshape(1,max_text_len)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "utv380x5eaeY",
    "outputId": "6a8d1791-2930-4bb0-cf52-5e777a583b7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "413"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "ukrSRX4IkZfR",
    "outputId": "ac55e971-9d60-4f6b-f748-cb7812204ce2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading https://files.pythonhosted.org/packages/63/ac/b93411318529980ab7f41e59ed64ec3ffed08ead32389e29eb78585dd55d/rouge-0.3.2-py3-none-any.whl\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-0.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cqB__YNlmq6u"
   },
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "evaluator = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OgMYStEym01j"
   },
   "outputs": [],
   "source": [
    "ans = evaluator.get_scores(decode_sequence(x_tr[20].reshape(1,max_text_len)),seq2summary(y_tr[20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "8z-gRZ5eiVXo",
    "outputId": "0e984ff1-0a98-487e-add2-b35b342851b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'f': 0.24999999500000009, 'p': 0.25, 'r': 0.25},\n",
       "  'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0},\n",
       "  'rouge-l': {'f': 0.2499999999995, 'p': 0.25, 'r': 0.25}}]"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4FQtYf0GnOPa"
   },
   "outputs": [],
   "source": [
    "metric = []\n",
    "for i in range(len(original)):\n",
    "  metric.append(evaluator.get_scores(predicted[i],original[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xeh2PmZZg_we"
   },
   "outputs": [],
   "source": [
    "avg_ro_1_r = 0\n",
    "for i in range(len(metric)):\n",
    "  avg_ro_1_r = avg_ro_1_r + metric[i][0]['rouge-1']['r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R_3FOyQdpUxA",
    "outputId": "134ef7b5-c146-48f0-f4e1-d27699ae2113"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.6813936668658185"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(avg_ro_1_r/len(metric))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2MP9X5twtiDB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
