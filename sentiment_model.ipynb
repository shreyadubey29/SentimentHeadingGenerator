{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import csv\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "\n",
    "def load_data(filename):\n",
    "    with open(filename) as csvfile:\n",
    "        readCSV = csv.reader(csvfile, delimiter=',')\n",
    "        textlines = []\n",
    "        sentiments = []\n",
    "        for row in readCSV:\n",
    "            textline = row[0]\n",
    "            sentiment = row[1]\n",
    "\n",
    "            textlines.append(textline)\n",
    "            sentiments.append(sentiment)\n",
    "\n",
    "    textlines.remove(textlines[0])\n",
    "    sentiments.remove(sentiments[0])\n",
    "    \n",
    "    return textlines, sentiments\n",
    "\n",
    "# loading data from news_summary_2.csv\n",
    "textlines, sentiments = load_data('sentiment_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary for expanding contractions\n",
    "\n",
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    newString = text.lower()\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])  \n",
    "    newString = re.sub(r'[^a-zA-Z0-9_\\s]+', '', newString)\n",
    "    return newString\n",
    "\n",
    "# cleaning the articles\n",
    "cleaned_text = []\n",
    "for t in textlines:\n",
    "    cleaned_text.append(text_cleaner(t))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame()\n",
    "data['text']=cleaned_text\n",
    "data['sentiments']=sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9994278739797086\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for i in data['text']:\n",
    "    if(len(i.split())<=35):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(data['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_len=35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "text =np.array(data['text'])\n",
    "sentiments=np.array(data['sentiments'])\n",
    "\n",
    "short_text=[]\n",
    "senti=[]\n",
    "\n",
    "for i in range(len(text)):\n",
    "    if(len(cleaned_text[i].split())<=max_text_len):\n",
    "        short_text.append(text[i])\n",
    "        senti.append(sentiments[i])\n",
    "        \n",
    "df=pd.DataFrame({'text':short_text,'sentiments':senti})\n",
    "export_csv = df.to_csv ('classifier_data.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data,test_data=train_test_split(df,test_size=0.1,random_state=0,shuffle=True)\n",
    "\n",
    "x_tr = train_data['text']\n",
    "x_val = test_data['text']\n",
    "y_tr = train_data['sentiments']\n",
    "y_val = test_data['sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the x_tr for training\n",
    "#export_csv = train_data.to_csv ('train_data.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 36.82070493638212\n",
      "Total Coverage of rare words: 1.4418483997352274\n"
     ]
    }
   ],
   "source": [
    "# Building tokenizer to convert word sequence into integer sequence\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "# Analysing the number of rare words in the vocabulary (rule: any word that appears 3 or leass times is rare)\n",
    "\n",
    "thresh=2\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)\n",
    "\n",
    "#prepare a tokenizer for articles on training data\n",
    "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class Attention(Model):\n",
    "    def __init__(self, units):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W1 = Dense(units)\n",
    "        self.W2 = Dense(units)\n",
    "        self.V = Dense(1)\n",
    " \n",
    "    def call(self, features, hidden):\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    " \n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(max_text_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_seq = Embedding(x_voc, 100, input_length=max_text_len)(sequence_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "rnn_cell_size = 128\n",
    "lstm = Bidirectional(LSTM(rnn_cell_size,dropout=0.3,return_sequences=True,return_state=True,\n",
    "                          recurrent_activation='relu',recurrent_initializer='glorot_uniform'))(embed_seq)\n",
    "lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional \\\n",
    "    (LSTM(rnn_cell_size,dropout=0.2,return_sequences=True,return_state=True,\n",
    "      recurrent_activation='relu',recurrent_initializer='glorot_uniform'))(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 35)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 35, 100)      2765900     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) [(None, 35, 256), (N 234496      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) [(None, 35, 256), (N 394240      bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_2[0][1]            \n",
      "                                                                 bidirectional_2[0][2]            \n",
      "                                                                 bidirectional_2[0][3]            \n",
      "                                                                 bidirectional_2[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 256)          0           bidirectional_3[0][1]            \n",
      "                                                                 bidirectional_3[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         [(None, 256), (None, 51501       bidirectional_3[0][0]            \n",
      "                                                                 concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1)            257         attention_3[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 3,446,394\n",
      "Trainable params: 3,446,394\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "state_h = Concatenate()([forward_h, backward_h])\n",
    "state_c = Concatenate()([forward_c, backward_c])\n",
    "\n",
    "attention = Attention(100)\n",
    "\n",
    "context_vector, attention_weights = attention(lstm, state_h)\n",
    " \n",
    "output = Dense(1, activation='sigmoid')(context_vector)\n",
    " \n",
    "model = Model(inputs=sequence_input, outputs=[output,attention_weights])\n",
    "#model = Model(inputs=sequence_input, outputs = output)\n",
    " \n",
    "# summarize layers\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    " \n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=1, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33015 samples, validate on 14150 samples\n",
      "Epoch 1/10\n",
      "33015/33015 [==============================] - 138s 4ms/sample - loss: 0.6390 - acc: 0.6721 - val_loss: 0.6216 - val_acc: 0.6711\n",
      "Epoch 2/10\n",
      "33015/33015 [==============================] - 138s 4ms/sample - loss: 0.5739 - acc: 0.6981 - val_loss: 0.6160 - val_acc: 0.6771\n",
      "Epoch 3/10\n",
      "33015/33015 [==============================] - 134s 4ms/sample - loss: 0.4895 - acc: 0.7611 - val_loss: 0.6664 - val_acc: 0.6624\n"
     ]
    }
   ],
   "source": [
    "#history = model.fit(x_tr,[y_tr,out[1]],epochs=10,batch_size=200,validation_split=.3, verbose=1, callbacks=[es])\n",
    "\n",
    "history = model.fit(x_tr,y_tr,epochs=10,batch_size=200,validation_split=.3, verbose=1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.predict(x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47165, 35, 1)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47165, 35)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = list(y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(y_tr)):\n",
    "    y_tr[i] = float(y_tr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of positives =  15479.0\n",
      "no. of negatives =  31686.0\n",
      "shape of x_tr =  (47165, 35)\n"
     ]
    }
   ],
   "source": [
    "print(\"no. of positives = \",np.sum(y_tr))\n",
    "print(\"no. of negatives = \",len(y_tr)-np.sum(y_tr))\n",
    "print(\"shape of x_tr = \",x_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of attention_weights =  (47165, 35, 1)\n",
      "shape of attention_weights =  (47165, 35)\n"
     ]
    }
   ],
   "source": [
    "trained_att = out[1]\n",
    "print(\"shape of attention_weights = \", trained_att.shape)\n",
    "new_trained_att = np.reshape(trained_att,(trained_att.shape[0],trained_att.shape[1]))\n",
    "print(\"shape of attention_weights = \", new_trained_att.shape)\n",
    "\n",
    "for i in range(new_trained_att.shape[0]):\n",
    "    avg = np.mean(new_trained_att[i,:])\n",
    "    for j in range(new_trained_att.shape[1]):\n",
    "        if(new_trained_att[i,j]>=avg):\n",
    "            new_trained_att[i,j]=1\n",
    "        else:\n",
    "            new_trained_att[i,j]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pos = np.empty((15479,35))\n",
    "x_neg = np.empty((31686,35))\n",
    "\n",
    "att_pos = np.empty((15479,35))\n",
    "att_neg = np.empty((31686,35))\n",
    "\n",
    "p,n = 0,0\n",
    "\n",
    "for i in range(len(y_tr)):\n",
    "    if(y_tr[i]==1):\n",
    "        x_pos[p,:] = x_tr[i,:]\n",
    "        att_pos[p,:] = new_trained_att[i,:]\n",
    "        p = p+1\n",
    "    elif(y_tr[i]==0):\n",
    "        x_neg[n,:] = x_tr[i,:]\n",
    "        att_neg[n,:] = new_trained_att[i,:]\n",
    "        n = n+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x_pos',x_pos)\n",
    "np.save('x_neg',x_neg)\n",
    "np.save('attn_pos',att_pos)\n",
    "np.save('attn_neg',att_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('attention_weights.npy',out[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_pos = np.sum(x_pos*att_pos,axis=0)\n",
    "context_attention = 1-att_pos\n",
    "s_cont = np.sum(x_pos*context_attention,axis=0)\n",
    "\n",
    "alpha = 100\n",
    "e = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "class Positive_Memory(Model):\n",
    "    def __init__(self, e, alpha):\n",
    "        super(Positive_Memory, self).__init__()\n",
    "        self.M_pos = np.ones((e,alpha))\n",
    " \n",
    "    def call(self, s_pos, s_cont):\n",
    "        w = softmax((s_pos.T)@self.M_pos)\n",
    "        self.M_pos = self.M_pos + np.outer(s_pos,w)\n",
    "        u = softmax((s_cont.T)@self.M_pos)\n",
    "        m_bar = np.sum(u*self.M_pos)\n",
    "        \n",
    "        return m_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 35)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 35, 100)      2765900     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 35, 100)      2765900     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 20), (None,  9680        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, 35, 20), (No 9680        embedding_3[0][0]                \n",
      "                                                                 lstm_4[0][1]                     \n",
      "                                                                 lstm_4[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 35, 27659)    580839      lstm_5[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 6,131,999\n",
      "Trainable params: 6,131,999\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 20\n",
    "embedding_dim = 100\n",
    "\n",
    "encoder_inputs = Input(shape=(max_text_len, ), dtype='int32',)\n",
    "encoder_embedding = Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "encoder_LSTM = LSTM(hidden_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_LSTM(encoder_embedding)\n",
    "\n",
    "pos_sentiment_memory = Positive_Memory(e,alpha)\n",
    "m_bar = pos_sentiment_memory(s_pos,s_cont)\n",
    "state_c1 = state_c + m_bar\n",
    "\n",
    "decoder_embedding = Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "decoder_LSTM = LSTM(hidden_dim, return_state=True, return_sequences=True)\n",
    "decoder_outputs, _, _ = decoder_LSTM(decoder_embedding, initial_state=[state_h, state_c])\n",
    "\n",
    "dense_layer = Dense(x_voc, activation='softmax')\n",
    "#outputs = TimeDistributed(Dense(x_voc, activation='softmax'))(decoder_outputs)\n",
    "outputs = dense_layer(decoder_outputs)\n",
    "final_model = Model(encoder_inputs, outputs)\n",
    "\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "15479/15479 [==============================] - 586s 38ms/sample - loss: 5.2647\n",
      "Epoch 2/50\n",
      "15479/15479 [==============================] - 566s 37ms/sample - loss: 5.1666\n",
      "Epoch 3/50\n",
      "15479/15479 [==============================] - 571s 37ms/sample - loss: 5.1085\n",
      "Epoch 4/50\n",
      "15479/15479 [==============================] - 563s 36ms/sample - loss: 5.0696\n",
      "Epoch 5/50\n",
      "15479/15479 [==============================] - 550s 36ms/sample - loss: 5.0418\n",
      "Epoch 6/50\n",
      "15479/15479 [==============================] - 571s 37ms/sample - loss: 5.0227\n",
      "Epoch 7/50\n",
      "15479/15479 [==============================] - 574s 37ms/sample - loss: 5.0052\n",
      "Epoch 8/50\n",
      "15479/15479 [==============================] - 574s 37ms/sample - loss: 4.9913\n",
      "Epoch 9/50\n",
      "15479/15479 [==============================] - 573s 37ms/sample - loss: 4.9794\n",
      "Epoch 10/50\n",
      "15479/15479 [==============================] - 575s 37ms/sample - loss: 4.9674\n",
      "Epoch 11/50\n",
      "15479/15479 [==============================] - 574s 37ms/sample - loss: 4.9558\n",
      "Epoch 12/50\n",
      "15479/15479 [==============================] - 576s 37ms/sample - loss: 4.9445\n",
      "Epoch 13/50\n",
      "15479/15479 [==============================] - 577s 37ms/sample - loss: 4.9333\n",
      "Epoch 14/50\n",
      "15479/15479 [==============================] - 574s 37ms/sample - loss: 4.9217\n",
      "Epoch 15/50\n",
      "15479/15479 [==============================] - 574s 37ms/sample - loss: 4.9108\n",
      "Epoch 16/50\n",
      "15479/15479 [==============================] - 563s 36ms/sample - loss: 4.9003\n",
      "Epoch 17/50\n",
      "15479/15479 [==============================] - 544s 35ms/sample - loss: 4.8897\n",
      "Epoch 18/50\n",
      "15479/15479 [==============================] - 546s 35ms/sample - loss: 4.8791\n",
      "Epoch 19/50\n",
      "15479/15479 [==============================] - 547s 35ms/sample - loss: 4.8700\n",
      "Epoch 20/50\n",
      "15479/15479 [==============================] - 544s 35ms/sample - loss: 4.8579\n",
      "Epoch 21/50\n",
      "15479/15479 [==============================] - 545s 35ms/sample - loss: 4.8468\n",
      "Epoch 22/50\n",
      "15479/15479 [==============================] - 544s 35ms/sample - loss: 4.8301\n",
      "Epoch 23/50\n",
      "15479/15479 [==============================] - 544s 35ms/sample - loss: 4.8123\n",
      "Epoch 24/50\n",
      "15479/15479 [==============================] - 543s 35ms/sample - loss: 4.7960\n",
      "Epoch 25/50\n",
      "15479/15479 [==============================] - 544s 35ms/sample - loss: 4.7802\n",
      "Epoch 26/50\n",
      "15479/15479 [==============================] - 548s 35ms/sample - loss: 4.7660\n",
      "Epoch 27/50\n",
      "15479/15479 [==============================] - 547s 35ms/sample - loss: 4.7514\n",
      "Epoch 28/50\n",
      "15479/15479 [==============================] - 544s 35ms/sample - loss: 4.7367\n",
      "Epoch 29/50\n",
      "15479/15479 [==============================] - 546s 35ms/sample - loss: 4.7233\n",
      "Epoch 30/50\n",
      "15479/15479 [==============================] - 543s 35ms/sample - loss: 4.7089\n",
      "Epoch 31/50\n",
      "15479/15479 [==============================] - 543s 35ms/sample - loss: 4.6942\n",
      "Epoch 32/50\n",
      "15479/15479 [==============================] - 545s 35ms/sample - loss: 4.6802\n",
      "Epoch 33/50\n",
      "15479/15479 [==============================] - 544s 35ms/sample - loss: 4.6663\n",
      "Epoch 34/50\n",
      "15479/15479 [==============================] - 545s 35ms/sample - loss: 4.6530\n",
      "Epoch 35/50\n",
      "15479/15479 [==============================] - 543s 35ms/sample - loss: 4.6403\n",
      "Epoch 36/50\n",
      "15479/15479 [==============================] - 546s 35ms/sample - loss: 4.6282\n",
      "Epoch 37/50\n",
      "15479/15479 [==============================] - 543s 35ms/sample - loss: 4.6163\n",
      "Epoch 38/50\n",
      "15479/15479 [==============================] - 544s 35ms/sample - loss: 4.6043\n",
      "Epoch 39/50\n",
      "15479/15479 [==============================] - 545s 35ms/sample - loss: 4.5938\n",
      "Epoch 40/50\n",
      "15479/15479 [==============================] - 546s 35ms/sample - loss: 4.5830\n",
      "Epoch 41/50\n",
      "15479/15479 [==============================] - 545s 35ms/sample - loss: 4.5704\n",
      "Epoch 42/50\n",
      "15479/15479 [==============================] - 544s 35ms/sample - loss: 4.5576\n",
      "Epoch 43/50\n",
      "15479/15479 [==============================] - 544s 35ms/sample - loss: 4.5457\n",
      "Epoch 44/50\n",
      "15479/15479 [==============================] - 543s 35ms/sample - loss: 4.5345\n",
      "Epoch 45/50\n",
      "15479/15479 [==============================] - 544s 35ms/sample - loss: 4.5231\n",
      "Epoch 46/50\n",
      "15479/15479 [==============================] - 544s 35ms/sample - loss: 4.5099\n",
      "Epoch 47/50\n",
      "15479/15479 [==============================] - 544s 35ms/sample - loss: 4.4980\n",
      "Epoch 48/50\n",
      "15479/15479 [==============================] - 545s 35ms/sample - loss: 4.4868\n",
      "Epoch 49/50\n",
      "15479/15479 [==============================] - 544s 35ms/sample - loss: 4.4747\n",
      "Epoch 50/50\n",
      "15479/15479 [==============================] - 543s 35ms/sample - loss: 4.4631\n"
     ]
    }
   ],
   "source": [
    "final_history = final_model.fit((x_pos*context_attention),x_pos, epochs=50 , batch_size=128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(final_history.history['loss'], label='train')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political and military leaders have concluded that it would be better for israel not to overthrow the hamas government in the gaza strip officials who took part in\n"
     ]
    }
   ],
   "source": [
    "sentence = []\n",
    "for j in (x_pos[10]):\n",
    "    if(j!=0):\n",
    "        sentence.append(x_tokenizer.index_word[j])\n",
    "        \n",
    "print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35,)\n"
     ]
    }
   ],
   "source": [
    "a = x_pos[10]\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = final_model.predict(x_pos[9:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 35, 27659)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 27659)\n"
     ]
    }
   ],
   "source": [
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[3.9737389e-04 8.4439462e-01 5.5298511e-02 ... 1.3321880e-10\n",
      "   9.7233197e-08 1.4851062e-10]\n",
      "  [4.1279194e-04 4.3840893e-03 5.2244011e-03 ... 1.6885822e-07\n",
      "   7.5822859e-06 1.8363259e-07]\n",
      "  [3.3615634e-02 1.4062191e-04 1.3812333e-03 ... 1.2417185e-08\n",
      "   1.3803078e-06 1.3351100e-08]\n",
      "  ...\n",
      "  [9.9821341e-01 3.0102306e-05 1.0714332e-04 ... 2.1064203e-12\n",
      "   1.0191362e-09 2.3513565e-12]\n",
      "  [9.9821556e-01 3.0124571e-05 1.0720467e-04 ... 2.0982044e-12\n",
      "   1.0161958e-09 2.3422570e-12]\n",
      "  [9.9821717e-01 3.0139130e-05 1.0724473e-04 ... 2.0929998e-12\n",
      "   1.0143267e-09 2.3364869e-12]]]\n",
      "(1, 35, 27659)\n"
     ]
    }
   ],
   "source": [
    "print(ans)\n",
    "print(ans.shape)\n",
    "a = ans[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 27659)\n"
     ]
    }
   ],
   "source": [
    "print(a.shape)\n",
    "\n",
    "b = np.empty((35))\n",
    "\n",
    "#print(a[0,:])\n",
    "\n",
    "for i in range(35):\n",
    "    b[i] = np.argmax(a[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.,   3.,   0.,   5.,   1.,   9.,   4.,   2.,   1.,   3.,   3.,\n",
       "         0.,   1.,   5., 179.,   0.,   6.,   3.,   6.,   4.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the of in the has to a the of of the in them and of and to\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "for j in (b):\n",
    "    if(j!=0):\n",
    "        predicted.append(x_tokenizer.index_word[j])\n",
    "\n",
    "print(' '.join(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
